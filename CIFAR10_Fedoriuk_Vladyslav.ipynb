{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CIFAR10_Fedoriuk_Vladyslav.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djq5H5QSK6hc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a576c7a4-9c1e-4689-d6ab-f5fa32ff286b"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLjbWVSwLRAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef897aa2-1cce-4b3f-a78a-311da5fdb8b2"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "train_images.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1l1_b4FLnAx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "3ddb4629-8dde-41d1-d797-ea37b2a280b4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "digit = train_images[4]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76yjbnbJLjsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70aedca-70fc-4b3a-e14d-965a94b14722"
      },
      "source": [
        "# MODIFY THE CODE TO ADD A VALIDATION SET\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_images = train_images\n",
        "train_labels = train_labels\n",
        "\n",
        "train_images = train_images.reshape((50000, 32, 32, 3))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 32, 32, 3))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "val_images = train_images[:10000]\n",
        "val_labels = train_labels[:10000]\n",
        "\n",
        "train_images = train_images[10000:]\n",
        "train_labels = train_labels[10000:]\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "# train_datagen.fit(train_images)\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "val_datagen.fit(val_images)\n",
        "\n",
        "train_images.shape, val_images.shape, train_labels.shape, val_labels.shape\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000, 32, 32, 3), (10000, 32, 32, 3), (40000, 10), (10000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIJilTuvRnDY"
      },
      "source": [
        "  # MAKE WHATEVER CHANGES ARE NECESSARY\n",
        "  # TO GET 0.7 ACCURACY ON THE TEST SET\n",
        "  \n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3 ,3), activation='relu', input_shape=(32, 32, 3), padding='same'))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "#model.add(layers.Dense(1024, activation='relu'))\n",
        "#model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr0xkEliYc-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a474094f-13b0-4a41-854b-226bf225177a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                16416     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 4,737,642\n",
            "Trainable params: 4,735,402\n",
            "Non-trainable params: 2,240\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUGKT6LNSJag"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=0.35)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdgz18QPNOVr",
        "outputId": "39e91bc4-73c7-439b-bec0-bfd5667a1f0a"
      },
      "source": [
        "  # MAKE WHATEVER CHANGES ARE NECESSARY\n",
        "  # TO GET 0.7 ACCURACY ON THE TEST SET\n",
        "epochs = 170\n",
        "model_hist = model.fit(\n",
        "    train_datagen.flow(train_images, train_labels, batch_size=32), \n",
        "    steps_per_epoch=len(train_images) / 32, \n",
        "    epochs=epochs, \n",
        "    validation_data=(val_images, val_labels))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/170\n",
            "1250/1250 [==============================] - 35s 21ms/step - loss: 2.3946 - accuracy: 0.1637 - val_loss: 1.8182 - val_accuracy: 0.2859\n",
            "Epoch 2/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 1.8238 - accuracy: 0.2962 - val_loss: 1.6381 - val_accuracy: 0.3787\n",
            "Epoch 3/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 1.6799 - accuracy: 0.3773 - val_loss: 1.7604 - val_accuracy: 0.3895\n",
            "Epoch 4/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 1.5369 - accuracy: 0.4467 - val_loss: 1.2863 - val_accuracy: 0.5242\n",
            "Epoch 5/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 1.4295 - accuracy: 0.4968 - val_loss: 1.1492 - val_accuracy: 0.5923\n",
            "Epoch 6/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 1.3481 - accuracy: 0.5314 - val_loss: 1.4076 - val_accuracy: 0.5257\n",
            "Epoch 7/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 1.2599 - accuracy: 0.5653 - val_loss: 1.0787 - val_accuracy: 0.6274\n",
            "Epoch 8/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 1.2111 - accuracy: 0.5913 - val_loss: 1.0773 - val_accuracy: 0.6401\n",
            "Epoch 9/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 1.1449 - accuracy: 0.6141 - val_loss: 0.9244 - val_accuracy: 0.6793\n",
            "Epoch 10/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 1.1090 - accuracy: 0.6282 - val_loss: 0.8885 - val_accuracy: 0.6936\n",
            "Epoch 11/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0696 - accuracy: 0.6463 - val_loss: 0.8593 - val_accuracy: 0.7040\n",
            "Epoch 12/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0441 - accuracy: 0.6545 - val_loss: 0.8139 - val_accuracy: 0.7259\n",
            "Epoch 13/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0077 - accuracy: 0.6697 - val_loss: 0.8860 - val_accuracy: 0.6985\n",
            "Epoch 14/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.9806 - accuracy: 0.6823 - val_loss: 0.8153 - val_accuracy: 0.7245\n",
            "Epoch 15/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.9591 - accuracy: 0.6925 - val_loss: 0.7768 - val_accuracy: 0.7366\n",
            "Epoch 16/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.9343 - accuracy: 0.6993 - val_loss: 0.9605 - val_accuracy: 0.6861\n",
            "Epoch 17/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.9203 - accuracy: 0.7078 - val_loss: 0.7330 - val_accuracy: 0.7563\n",
            "Epoch 18/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8936 - accuracy: 0.7127 - val_loss: 0.9469 - val_accuracy: 0.7023\n",
            "Epoch 19/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8693 - accuracy: 0.7212 - val_loss: 0.7780 - val_accuracy: 0.7454\n",
            "Epoch 20/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8521 - accuracy: 0.7274 - val_loss: 0.8340 - val_accuracy: 0.7291\n",
            "Epoch 21/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8378 - accuracy: 0.7326 - val_loss: 0.7382 - val_accuracy: 0.7556\n",
            "Epoch 22/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8459 - accuracy: 0.7332 - val_loss: 0.6872 - val_accuracy: 0.7772\n",
            "Epoch 23/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8105 - accuracy: 0.7420 - val_loss: 0.5775 - val_accuracy: 0.8102\n",
            "Epoch 24/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.7860 - accuracy: 0.7473 - val_loss: 0.6911 - val_accuracy: 0.7762\n",
            "Epoch 25/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.7778 - accuracy: 0.7500 - val_loss: 0.6460 - val_accuracy: 0.7914\n",
            "Epoch 26/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.7568 - accuracy: 0.7604 - val_loss: 0.6010 - val_accuracy: 0.7984\n",
            "Epoch 27/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.7579 - accuracy: 0.7616 - val_loss: 0.5655 - val_accuracy: 0.8113\n",
            "Epoch 28/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.7564 - accuracy: 0.7617 - val_loss: 0.5837 - val_accuracy: 0.8103\n",
            "Epoch 29/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.7355 - accuracy: 0.7683 - val_loss: 0.5613 - val_accuracy: 0.8145\n",
            "Epoch 30/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.7334 - accuracy: 0.7678 - val_loss: 0.7079 - val_accuracy: 0.7740\n",
            "Epoch 31/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.7370 - accuracy: 0.7661 - val_loss: 0.6179 - val_accuracy: 0.7982\n",
            "Epoch 32/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.7212 - accuracy: 0.7698 - val_loss: 0.5278 - val_accuracy: 0.8217\n",
            "Epoch 33/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.7083 - accuracy: 0.7782 - val_loss: 0.5099 - val_accuracy: 0.8274\n",
            "Epoch 34/170\n",
            "1250/1250 [==============================] - 26s 20ms/step - loss: 0.7102 - accuracy: 0.7739 - val_loss: 0.6692 - val_accuracy: 0.7840\n",
            "Epoch 35/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6795 - accuracy: 0.7829 - val_loss: 0.5959 - val_accuracy: 0.8053\n",
            "Epoch 36/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6879 - accuracy: 0.7826 - val_loss: 0.5154 - val_accuracy: 0.8285\n",
            "Epoch 37/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6801 - accuracy: 0.7861 - val_loss: 0.5215 - val_accuracy: 0.8263\n",
            "Epoch 38/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6727 - accuracy: 0.7887 - val_loss: 0.4790 - val_accuracy: 0.8393\n",
            "Epoch 39/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6600 - accuracy: 0.7909 - val_loss: 0.4814 - val_accuracy: 0.8366\n",
            "Epoch 40/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6603 - accuracy: 0.7920 - val_loss: 0.5442 - val_accuracy: 0.8211\n",
            "Epoch 41/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6520 - accuracy: 0.7942 - val_loss: 0.5085 - val_accuracy: 0.8298\n",
            "Epoch 42/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6350 - accuracy: 0.7996 - val_loss: 0.5587 - val_accuracy: 0.8177\n",
            "Epoch 43/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6341 - accuracy: 0.8008 - val_loss: 0.5089 - val_accuracy: 0.8381\n",
            "Epoch 44/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6202 - accuracy: 0.8037 - val_loss: 0.7486 - val_accuracy: 0.7648\n",
            "Epoch 45/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6210 - accuracy: 0.8028 - val_loss: 0.5619 - val_accuracy: 0.8171\n",
            "Epoch 46/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6299 - accuracy: 0.8023 - val_loss: 0.5193 - val_accuracy: 0.8324\n",
            "Epoch 47/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6129 - accuracy: 0.8062 - val_loss: 0.4810 - val_accuracy: 0.8406\n",
            "Epoch 48/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6225 - accuracy: 0.8025 - val_loss: 0.5190 - val_accuracy: 0.8336\n",
            "Epoch 49/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6206 - accuracy: 0.8076 - val_loss: 0.4771 - val_accuracy: 0.8449\n",
            "Epoch 50/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5887 - accuracy: 0.8139 - val_loss: 0.4483 - val_accuracy: 0.8529\n",
            "Epoch 51/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6072 - accuracy: 0.8102 - val_loss: 0.4868 - val_accuracy: 0.8384\n",
            "Epoch 52/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5849 - accuracy: 0.8156 - val_loss: 0.5831 - val_accuracy: 0.8151\n",
            "Epoch 53/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5863 - accuracy: 0.8159 - val_loss: 0.6430 - val_accuracy: 0.7962\n",
            "Epoch 54/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5934 - accuracy: 0.8152 - val_loss: 0.4316 - val_accuracy: 0.8560\n",
            "Epoch 55/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5748 - accuracy: 0.8174 - val_loss: 0.4690 - val_accuracy: 0.8454\n",
            "Epoch 56/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5708 - accuracy: 0.8182 - val_loss: 0.4788 - val_accuracy: 0.8404\n",
            "Epoch 57/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5682 - accuracy: 0.8183 - val_loss: 0.4459 - val_accuracy: 0.8519\n",
            "Epoch 58/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5614 - accuracy: 0.8240 - val_loss: 0.4992 - val_accuracy: 0.8380\n",
            "Epoch 59/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5548 - accuracy: 0.8256 - val_loss: 0.5753 - val_accuracy: 0.8118\n",
            "Epoch 60/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5552 - accuracy: 0.8241 - val_loss: 0.4573 - val_accuracy: 0.8554\n",
            "Epoch 61/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5597 - accuracy: 0.8258 - val_loss: 0.4337 - val_accuracy: 0.8588\n",
            "Epoch 62/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5544 - accuracy: 0.8246 - val_loss: 0.4771 - val_accuracy: 0.8431\n",
            "Epoch 63/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5381 - accuracy: 0.8294 - val_loss: 0.4595 - val_accuracy: 0.8517\n",
            "Epoch 64/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5441 - accuracy: 0.8294 - val_loss: 0.4708 - val_accuracy: 0.8501\n",
            "Epoch 65/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5494 - accuracy: 0.8280 - val_loss: 0.4660 - val_accuracy: 0.8503\n",
            "Epoch 66/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5204 - accuracy: 0.8356 - val_loss: 0.4383 - val_accuracy: 0.8592\n",
            "Epoch 67/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5384 - accuracy: 0.8293 - val_loss: 0.4652 - val_accuracy: 0.8454\n",
            "Epoch 68/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5218 - accuracy: 0.8362 - val_loss: 0.4498 - val_accuracy: 0.8568\n",
            "Epoch 69/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5218 - accuracy: 0.8355 - val_loss: 0.4613 - val_accuracy: 0.8460\n",
            "Epoch 70/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5328 - accuracy: 0.8302 - val_loss: 0.4622 - val_accuracy: 0.8535\n",
            "Epoch 71/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5236 - accuracy: 0.8371 - val_loss: 0.4845 - val_accuracy: 0.8464\n",
            "Epoch 72/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5153 - accuracy: 0.8388 - val_loss: 0.4247 - val_accuracy: 0.8625\n",
            "Epoch 73/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5053 - accuracy: 0.8399 - val_loss: 0.5027 - val_accuracy: 0.8391\n",
            "Epoch 74/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5127 - accuracy: 0.8406 - val_loss: 0.4229 - val_accuracy: 0.8604\n",
            "Epoch 75/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5148 - accuracy: 0.8401 - val_loss: 0.4654 - val_accuracy: 0.8539\n",
            "Epoch 76/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5150 - accuracy: 0.8379 - val_loss: 0.4854 - val_accuracy: 0.8474\n",
            "Epoch 77/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5104 - accuracy: 0.8418 - val_loss: 0.4773 - val_accuracy: 0.8487\n",
            "Epoch 78/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4992 - accuracy: 0.8411 - val_loss: 0.4348 - val_accuracy: 0.8617\n",
            "Epoch 79/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4935 - accuracy: 0.8430 - val_loss: 0.4385 - val_accuracy: 0.8608\n",
            "Epoch 80/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4884 - accuracy: 0.8471 - val_loss: 0.4138 - val_accuracy: 0.8640\n",
            "Epoch 81/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4806 - accuracy: 0.8490 - val_loss: 0.4239 - val_accuracy: 0.8661\n",
            "Epoch 82/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4946 - accuracy: 0.8434 - val_loss: 0.4879 - val_accuracy: 0.8479\n",
            "Epoch 83/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4855 - accuracy: 0.8469 - val_loss: 0.4118 - val_accuracy: 0.8654\n",
            "Epoch 84/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4765 - accuracy: 0.8488 - val_loss: 0.4504 - val_accuracy: 0.8565\n",
            "Epoch 85/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4734 - accuracy: 0.8507 - val_loss: 0.4557 - val_accuracy: 0.8538\n",
            "Epoch 86/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4715 - accuracy: 0.8518 - val_loss: 0.4275 - val_accuracy: 0.8630\n",
            "Epoch 87/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4733 - accuracy: 0.8496 - val_loss: 0.4326 - val_accuracy: 0.8588\n",
            "Epoch 88/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4692 - accuracy: 0.8517 - val_loss: 0.4735 - val_accuracy: 0.8532\n",
            "Epoch 89/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4837 - accuracy: 0.8484 - val_loss: 0.3943 - val_accuracy: 0.8688\n",
            "Epoch 90/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4769 - accuracy: 0.8539 - val_loss: 0.4147 - val_accuracy: 0.8648\n",
            "Epoch 91/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4676 - accuracy: 0.8540 - val_loss: 0.3805 - val_accuracy: 0.8758\n",
            "Epoch 92/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4486 - accuracy: 0.8568 - val_loss: 0.3871 - val_accuracy: 0.8726\n",
            "Epoch 93/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4543 - accuracy: 0.8566 - val_loss: 0.4213 - val_accuracy: 0.8644\n",
            "Epoch 94/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4579 - accuracy: 0.8547 - val_loss: 0.4635 - val_accuracy: 0.8547\n",
            "Epoch 95/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4487 - accuracy: 0.8581 - val_loss: 0.4006 - val_accuracy: 0.8761\n",
            "Epoch 96/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4577 - accuracy: 0.8553 - val_loss: 0.3811 - val_accuracy: 0.8779\n",
            "Epoch 97/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4557 - accuracy: 0.8557 - val_loss: 0.4245 - val_accuracy: 0.8609\n",
            "Epoch 98/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4446 - accuracy: 0.8595 - val_loss: 0.4042 - val_accuracy: 0.8716\n",
            "Epoch 99/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4621 - accuracy: 0.8553 - val_loss: 0.4076 - val_accuracy: 0.8671\n",
            "Epoch 100/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4460 - accuracy: 0.8604 - val_loss: 0.4787 - val_accuracy: 0.8502\n",
            "Epoch 101/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4541 - accuracy: 0.8574 - val_loss: 0.3922 - val_accuracy: 0.8745\n",
            "Epoch 102/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4482 - accuracy: 0.8609 - val_loss: 0.4090 - val_accuracy: 0.8709\n",
            "Epoch 103/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4366 - accuracy: 0.8622 - val_loss: 0.4653 - val_accuracy: 0.8540\n",
            "Epoch 104/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4414 - accuracy: 0.8626 - val_loss: 0.3577 - val_accuracy: 0.8829\n",
            "Epoch 105/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4407 - accuracy: 0.8626 - val_loss: 0.3903 - val_accuracy: 0.8779\n",
            "Epoch 106/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4333 - accuracy: 0.8627 - val_loss: 0.4528 - val_accuracy: 0.8582\n",
            "Epoch 107/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4374 - accuracy: 0.8617 - val_loss: 0.3990 - val_accuracy: 0.8732\n",
            "Epoch 108/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4443 - accuracy: 0.8614 - val_loss: 0.3927 - val_accuracy: 0.8735\n",
            "Epoch 109/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4358 - accuracy: 0.8637 - val_loss: 0.4163 - val_accuracy: 0.8661\n",
            "Epoch 110/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4331 - accuracy: 0.8657 - val_loss: 0.3950 - val_accuracy: 0.8722\n",
            "Epoch 111/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4346 - accuracy: 0.8640 - val_loss: 0.3899 - val_accuracy: 0.8748\n",
            "Epoch 112/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4338 - accuracy: 0.8662 - val_loss: 0.3893 - val_accuracy: 0.8709\n",
            "Epoch 113/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4202 - accuracy: 0.8682 - val_loss: 0.4084 - val_accuracy: 0.8656\n",
            "Epoch 114/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4199 - accuracy: 0.8678 - val_loss: 0.3549 - val_accuracy: 0.8864\n",
            "Epoch 115/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4189 - accuracy: 0.8692 - val_loss: 0.3477 - val_accuracy: 0.8833\n",
            "Epoch 116/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4186 - accuracy: 0.8681 - val_loss: 0.4330 - val_accuracy: 0.8637\n",
            "Epoch 117/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4185 - accuracy: 0.8682 - val_loss: 0.4061 - val_accuracy: 0.8720\n",
            "Epoch 118/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4163 - accuracy: 0.8664 - val_loss: 0.4146 - val_accuracy: 0.8699\n",
            "Epoch 119/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4199 - accuracy: 0.8669 - val_loss: 0.4087 - val_accuracy: 0.8693\n",
            "Epoch 120/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4073 - accuracy: 0.8706 - val_loss: 0.4015 - val_accuracy: 0.8741\n",
            "Epoch 121/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4180 - accuracy: 0.8685 - val_loss: 0.4002 - val_accuracy: 0.8740\n",
            "Epoch 122/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4155 - accuracy: 0.8717 - val_loss: 0.3467 - val_accuracy: 0.8893\n",
            "Epoch 123/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4100 - accuracy: 0.8695 - val_loss: 0.4231 - val_accuracy: 0.8641\n",
            "Epoch 124/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4148 - accuracy: 0.8715 - val_loss: 0.4356 - val_accuracy: 0.8631\n",
            "Epoch 125/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4073 - accuracy: 0.8719 - val_loss: 0.3725 - val_accuracy: 0.8805\n",
            "Epoch 126/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4103 - accuracy: 0.8705 - val_loss: 0.3777 - val_accuracy: 0.8769\n",
            "Epoch 127/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4136 - accuracy: 0.8701 - val_loss: 0.3687 - val_accuracy: 0.8799\n",
            "Epoch 128/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3960 - accuracy: 0.8737 - val_loss: 0.3955 - val_accuracy: 0.8748\n",
            "Epoch 129/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4085 - accuracy: 0.8727 - val_loss: 0.3967 - val_accuracy: 0.8773\n",
            "Epoch 130/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4089 - accuracy: 0.8724 - val_loss: 0.3950 - val_accuracy: 0.8738\n",
            "Epoch 131/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3994 - accuracy: 0.8764 - val_loss: 0.3461 - val_accuracy: 0.8860\n",
            "Epoch 132/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3899 - accuracy: 0.8735 - val_loss: 0.4179 - val_accuracy: 0.8678\n",
            "Epoch 133/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3917 - accuracy: 0.8770 - val_loss: 0.3723 - val_accuracy: 0.8803\n",
            "Epoch 134/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3882 - accuracy: 0.8754 - val_loss: 0.3921 - val_accuracy: 0.8759\n",
            "Epoch 135/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4006 - accuracy: 0.8745 - val_loss: 0.3690 - val_accuracy: 0.8853\n",
            "Epoch 136/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3980 - accuracy: 0.8760 - val_loss: 0.3636 - val_accuracy: 0.8816\n",
            "Epoch 137/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3960 - accuracy: 0.8777 - val_loss: 0.3949 - val_accuracy: 0.8759\n",
            "Epoch 138/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3971 - accuracy: 0.8782 - val_loss: 0.3859 - val_accuracy: 0.8763\n",
            "Epoch 139/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3767 - accuracy: 0.8808 - val_loss: 0.3875 - val_accuracy: 0.8775\n",
            "Epoch 140/170\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3859 - accuracy: 0.8797 - val_loss: 0.4984 - val_accuracy: 0.8524\n",
            "Epoch 141/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3892 - accuracy: 0.8762 - val_loss: 0.3530 - val_accuracy: 0.8845\n",
            "Epoch 142/170\n",
            "1250/1250 [==============================] - 26s 20ms/step - loss: 0.3867 - accuracy: 0.8788 - val_loss: 0.3766 - val_accuracy: 0.8775\n",
            "Epoch 143/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3875 - accuracy: 0.8797 - val_loss: 0.3615 - val_accuracy: 0.8826\n",
            "Epoch 144/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3889 - accuracy: 0.8772 - val_loss: 0.3966 - val_accuracy: 0.8748\n",
            "Epoch 145/170\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3828 - accuracy: 0.8820 - val_loss: 0.3699 - val_accuracy: 0.8828\n",
            "Epoch 146/170\n",
            "1250/1250 [==============================] - 26s 20ms/step - loss: 0.3748 - accuracy: 0.8825 - val_loss: 0.3927 - val_accuracy: 0.8762\n",
            "Epoch 147/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3787 - accuracy: 0.8817 - val_loss: 0.3790 - val_accuracy: 0.8795\n",
            "Epoch 148/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3819 - accuracy: 0.8809 - val_loss: 0.3664 - val_accuracy: 0.8829\n",
            "Epoch 149/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3682 - accuracy: 0.8828 - val_loss: 0.3789 - val_accuracy: 0.8823\n",
            "Epoch 150/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3769 - accuracy: 0.8826 - val_loss: 0.3669 - val_accuracy: 0.8842\n",
            "Epoch 151/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3757 - accuracy: 0.8804 - val_loss: 0.3798 - val_accuracy: 0.8811\n",
            "Epoch 152/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3765 - accuracy: 0.8803 - val_loss: 0.4063 - val_accuracy: 0.8760\n",
            "Epoch 153/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3635 - accuracy: 0.8835 - val_loss: 0.3511 - val_accuracy: 0.8883\n",
            "Epoch 154/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3838 - accuracy: 0.8802 - val_loss: 0.4077 - val_accuracy: 0.8681\n",
            "Epoch 155/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3691 - accuracy: 0.8844 - val_loss: 0.3823 - val_accuracy: 0.8751\n",
            "Epoch 156/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3743 - accuracy: 0.8824 - val_loss: 0.3434 - val_accuracy: 0.8912\n",
            "Epoch 157/170\n",
            "1250/1250 [==============================] - 27s 21ms/step - loss: 0.3604 - accuracy: 0.8883 - val_loss: 0.3481 - val_accuracy: 0.8905\n",
            "Epoch 158/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3615 - accuracy: 0.8838 - val_loss: 0.3989 - val_accuracy: 0.8737\n",
            "Epoch 159/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3662 - accuracy: 0.8830 - val_loss: 0.3512 - val_accuracy: 0.8864\n",
            "Epoch 160/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3625 - accuracy: 0.8869 - val_loss: 0.3560 - val_accuracy: 0.8858\n",
            "Epoch 161/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3590 - accuracy: 0.8867 - val_loss: 0.4139 - val_accuracy: 0.8713\n",
            "Epoch 162/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3598 - accuracy: 0.8870 - val_loss: 0.3321 - val_accuracy: 0.8912\n",
            "Epoch 163/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3572 - accuracy: 0.8861 - val_loss: 0.3261 - val_accuracy: 0.8967\n",
            "Epoch 164/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3709 - accuracy: 0.8825 - val_loss: 0.3907 - val_accuracy: 0.8799\n",
            "Epoch 165/170\n",
            "1250/1250 [==============================] - 27s 21ms/step - loss: 0.3628 - accuracy: 0.8857 - val_loss: 0.4033 - val_accuracy: 0.8749\n",
            "Epoch 166/170\n",
            "1250/1250 [==============================] - 27s 21ms/step - loss: 0.3613 - accuracy: 0.8867 - val_loss: 0.4061 - val_accuracy: 0.8715\n",
            "Epoch 167/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3529 - accuracy: 0.8881 - val_loss: 0.3747 - val_accuracy: 0.8794\n",
            "Epoch 168/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3570 - accuracy: 0.8888 - val_loss: 0.4043 - val_accuracy: 0.8775\n",
            "Epoch 169/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3518 - accuracy: 0.8893 - val_loss: 0.3527 - val_accuracy: 0.8852\n",
            "Epoch 170/170\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3500 - accuracy: 0.8892 - val_loss: 0.3283 - val_accuracy: 0.8927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK7GvOCaUwp9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "8bfa21da-6099-4d4c-9015-07ea96e961e1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(0, epochs)\n",
        "train_loss = model_hist.history['loss']\n",
        "val_loss= model_hist.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, val_loss, 'b+', label='Validation')\n",
        "plt.plot(epochs, train_loss, 'bo', label='training')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEGCAYAAACZ0MnKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7xVdZ3/8dcHpBAl5TblQ/SAjhdE4uLRLDTUzNAKikylo4Na8RB1pn41/sZ+/KZzsOExTTr9ykwNJ7oISeZt6Jfmhbz1U8sDAoo3Lh0UxxLxRgMql8/vj7UWrLPYa++1z76f/X4+Huux1/6uy/7uzWZ/zvdu7o6IiEgWfWqdARERaRwKGiIikpmChoiIZKagISIimSloiIhIZnvVOgPlNHToUB8xYkStsyEi0jCWLl36qrsPy3p+rwoaI0aMoLOzs9bZEBFpGGa2vpjzVT0lIiKZKWiIiEhmChoiIpJZr2rTEJHeY9u2bWzYsIG333671lnpFfr378/w4cPp169fSfdR0BCRurRhwwYGDhzIiBEjMLNaZ6ehuTubNm1iw4YNjBw5sqR7NX311MKFMGIE9OkTPC5cWOsciQjA22+/zZAhQxQwysDMGDJkSFlKbU1d0li4EGbOhC1bgufr1wfPAdraapcvEQkoYJRPuT7Lpi5pzJ69O2BEtmwJ0kVEZE9NHTReeKG4dBFpHieffDJ33313t7Tvfe97zJo1K+f5J5100q7BxWeccQZvvPHGHud0dHRw1VVX5X3dO+64g6effnrX829+85vcd999xWa/Ypo6aBx8cHHpIlL/OjrKc5/p06ezaNGibmmLFi1i+vTpBa+988472X///Xv0usmgccUVV3Dqqaf26F6V0NRBY+5cGDCge9qAAUG6iDSmOXPKc58zzzyT3/zmN7z77rsAdHV18V//9V/cdNNNtLa2Mnr0aNrb23NeO2LECF599VUA5s6dy+GHH84JJ5zAc889t+ucG264gWOPPZaxY8fyuc99ji1btvDII4+wePFiLrvsMsaNG8fatWs5//zzueWWWwBYsmQJ48ePZ8yYMVx44YW88847u16vvb2dCRMmMGbMGJ599tnyfAg5NHXQaGuDefOgpQXMgsd589QILiIwePBgjjvuOO666y4gKGWcddZZzJ07l87OTlauXMmDDz7IypUrU++xdOlSFi1axPLly7nzzjt5/PHHdx2bNm0ajz/+OCtWrGDUqFH8+Mc/5iMf+QhTpkzhyiuvZPny5Rx66KG7zn/77bc5//zz+eUvf8mTTz7J9u3bue6663YdHzp0KMuWLWPWrFkFq8BK0dRBA4IA0dUFO3cGjwoYIo2noyP4wy/qIBTtl1pVFa+iiqqmbr75ZiZMmMD48eNZtWpVt6qkpIcffpjPfvazDBgwgPe9731MmTJl17GnnnqKE088kTFjxrBw4UJWrVqVNy/PPfccI0eO5PDDDwdgxowZPPTQQ7uOT5s2DYBjjjmGrq6unr7lgpo+aIhI4+voAPdgg937pQaNqVOnsmTJEpYtW8aWLVsYPHgwV111FUuWLGHlypV88pOf7PHYh/PPP59rrrmGJ598kvb29pLHULz3ve8FoG/fvmzfvr2ke+WjoCEikmLffffl5JNP5sILL2T69Om89dZb7LPPPuy333785S9/2VV1leajH/0od9xxB1u3bmXz5s38+te/3nVs8+bNHHDAAWzbto2FsVHFAwcOZPPmzXvc64gjjqCrq4s1a9YAcOONNzJp0qQyvdPsFDREpFdJaZvusenTp7NixQqmT5/O2LFjGT9+PEceeSRf+MIXmDhxYt5rJ0yYwNlnn83YsWM5/fTTOfbYY3cd+9a3vsWHPvQhJk6cyJFHHrkr/ZxzzuHKK69k/PjxrF27dld6//79+clPfsLnP/95xowZQ58+fbjooovK+2YzMI/Kc71Aa2uraxEmkd7hmWeeYdSoUbXORq+S6zM1s6Xu3pr1HippiIhIZgoaIiKSmYKGiIhkVrGgYWYHmdn9Zva0ma0ys6/kOMfM7GozW2NmK81sQuzYDDNbHW4zKpVPERHJrpJTo28Hvu7uy8xsILDUzO519/hImNOBw8LtQ8B1wIfMbDDQDrQCHl672N1fr2B+RUSkgIqVNNz9ZXdfFu5vBp4BDkycNhX4uQceA/Y3swOATwD3uvtrYaC4F5hcqbyKiEg2VWnTMLMRwHjgD4lDBwIvxp5vCNPS0nPde6aZdZpZ58aNG8uVZRFpcm+88QbXXntt0delTYseV2/TnRej4kHDzPYFbgW+6u5vlfv+7j7P3VvdvXXYsGHlvr2INIhyL92cFjQKTdGRZVr0epvuvBgVDRpm1o8gYCx099tynPIScFDs+fAwLS1dRGQP0dLN69cHc05FSzeXEjguv/xy1q5dy7hx4zj22GM58cQTmTJlCkcddRQAn/nMZzjmmGMYPXo08+bN23VdNC16V1cXo0aN4stf/jKjR4/mtNNOY+vWrQDdpjtPm9Z848aNfPzjH2f06NF86UtfoqWlZdd067VUyd5TBvwYeMbdv5ty2mLg78JeVMcDb7r7y8DdwGlmNsjMBgGnhWkiInuoxNLN3/72tzn00ENZvnw5V155JcuWLeP73/8+zz//PADz589n6dKldHZ2cvXVV7Np06Y97rF69WouueQSVq1axf7778+tt96a87VyTWs+Z84cTjnlFFatWsWZZ57JC3WypGgle09NBM4DnjSz5WHa/wIOBnD364E7gTOANcAW4ILw2Gtm9i0gmnz+Cnd/rYJ5FZEGVo2lm4877jhGjhy56/nVV1/N7bffDsCLL77I6tWrGTJkSLdrRo4cybhx44D8U5bHpzW/7bagUub3v//9rvtPnjyZQYMGle/NlKBiQcPdfw9YgXMcuCTl2HxgfgWyJiK9zMEHB1VSudLLZZ999tm1/8ADD3Dffffx6KOPMmDAAE466aScU5tH05VDMGV5VD2Vdl6lpzUvB40IF5GGV4mlm9OmKAd48803GTRoEAMGDODZZ5/lscce6/kLpZg4cSI333wzAPfccw+vv14fw9QUNESk4VVi6eYhQ4YwceJEjj76aC677LJuxyZPnsz27dsZNWoUl19+Occff3yJ72BP7e3t3HPPPRx99NH86le/4gMf+AADBw4s++sUS1Oji0hdavap0d955x369u3LXnvtxaOPPsqsWbNYvnx54QvzKMfU6JVsCBcRkR564YUXOOuss9i5cyfvec97uOGGG2qdJUBBQ0SkLh122GE88cQTtc7GHtSmISJ1qzdVn9dauT5LBQ0RqUv9+/dn06ZNChxl4O5s2rSJ/v37l3wvVU+JSF0aPnw4GzZsQBORlkf//v0ZPnx4yfdR0BCRutSvX79uI7ClPqh6SkREMlPQEBGRzBQ0Qh0dtc6BiEj9U9AIzZlT6xyIiNQ/BQ0REcmsqYNGR0cwuZmFE7hH+6qqEhHJTRMWhsyCZSJFRJpJsRMWNnVJI6mci9KLiPRGGtxHECD69du98le0KD2UNh+/iEhvU7GShpnNN7NXzOyplOOXmdnycHvKzHaY2eDwWJeZPRkeq/gCGbNnw7Zt3dNKXZReRKQ3qmT11E+ByWkH3f1Kdx/n7uOAbwAPuvtrsVNODo9nrmvrqWosSi8i0htULGi4+0PAawVPDEwHbqpUXgpJW3zeXT2pRETiat4QbmYDCEokt8aSHbjHzJaa2cwC1880s04z6+zpbJhpi9IvWKCgISISV/OgAXwa+H+JqqkT3H0CcDpwiZl9NO1id5/n7q3u3jps2LAeZSC5KD2Uvii9iEhvVA9B4xwSVVPu/lL4+ApwO3BcpTPR1gZdXbBzJ7S3K2CIiORS06BhZvsBk4D/jKXtY2YDo33gNCBnD6xKUZWUiEhuFRunYWY3AScBQ81sA9AO9ANw9+vD0z4L3OPu/x279P3A7RbUE+0F/MLdf1upfIqISHYVCxruPj3DOT8l6JobT1sHjK1MrkREpBT10KYhIiINQkFDREQyU9AQEZHMFDRiFi7UTLciIvloltvQwoXBzLZbtgTPNdOtiMieVNIIzZ69O2BENNOtiEh3ChohzXQrIlKYggbBCPC0pV7TZsAVEWlGChoEQWPBgtwz3c6dW5MsiYjUJQWNUDTTLQQz3ba0aKZbEZEk9Z6KaWuD1as1YaGISBqVNBIUMERE0iloiIhIZgoaIiKSmYKGiIhkpqAhIiKZKWiIiEhmBYOGmU0M1+rGzM41s++aWUvls1Y7mu1WRCS3LCWN64AtZjYW+DqwFvh5RXNVQ9Fst+vXB1OLRLPdKnCIiGQLGtvd3YGpwDXu/kNgYKGLzGy+mb1iZk+lHD/JzN40s+Xh9s3Ysclm9pyZrTGzy7O+mXLQbLciIumyjAjfbGbfAM4FPmpmfYB+Ga77KXAN+UslD7v7p+IJZtYX+CHwcWAD8LiZLXb3pzO8Zsk0262ISLosJY2zgXeAL7r7n4HhwJWFLnL3h4DXepCn44A17r7O3d8FFhGUcqoibVZbzXYrIpItaGwGvu/uD5vZ4cA44KYyvf6HzWyFmd1lZqPDtAOBF2PnbAjTcjKzmWbWaWadGzduLDlDc+dqtlsRkTRZgsZDwHvN7EDgHuA8gqqnUi0DWtx9LPAD4I6e3MTd57l7q7u3Dhs2rORMRbPdtrRotlsRkaQsQcPcfQswDbjW3T8PHF3qC7v7W+7+13D/TqCfmQ0FXgIOip06PEyrmrY26OqCnTuDRwUMEZFApqBhZh8G2oDfFHFdoZt+wMws3D8uvOcm4HHgMDMbaWbvAc4BFpf6eiIiUrosvae+CnwDuN3dV5nZIcD9hS4ys5uAk4ChZrYBaCfsdeXu1wNnArPMbDuwFTgn7Nq73cwuBe4G+gLz3X1V0e9MRETKzjxtcezkiWb7AkRVSvWotbXVOzs7a50NEZGGYWZL3b016/lZphEZY2ZPAKuAp81saaynU6+m6URERLrLUj31I+Br7n4/BCO5gRuAj1QwXzUXTScSjQ5fvx4uuCDYV8O4iDSrLA3a+0QBA8DdHwD2qViO6kSu6US2bdN0IiLS3LKUNNaZ2T8DN4bPzwXWVS5L9UHTiYiI7ClLSeNCYBhwW7gNC9N6tbRpQ9yDQX8dHVXNjohIXShY0nD314F/qEJe6srcud3bNCILFqhNQ0SaV2rQMLNfA6n9cd19SkVyVCeiwDB7dlAldfDBQWO4AoaINLN8JY2rqpaLOtXW1j1IqEpKRJpdatBw9wermZFGoKAhIs2u5DmkRESkeShoZKCR4SIigSzjNJparpHhM2cG+2oUF5FmU3DCwnC1vsuAFmJBxt1PqWzWileJCQtHjAgCRVJLS7DWhohIIyt2wsIsJY1fAdcTzDe1o6cZa1QaGS4isluWoLHd3a+reE7qUEfH7vEZSWkjxkVEerMsDeG/NrOLzewAMxscbRXPWR2YMycYGT5gQPf0AQOCdBGRZpOlpDEjfLwslubAIeXPTv3JNTJ87lw1gotIc8oy99TIamSkXnR0BCWMSLCKObS3a3CfiEiWlfv6mdk/mNkt4XapmfXLcN18M3vFzJ5KOd5mZivN7Ekze8TMxsaOdYXpy82squu3dnQEM9lGncqi/Y4OjdcQEclSPXUd0A+4Nnx+Xpj2pQLX/RS4Bvh5yvE/AZPc/XUzOx2YB3wodvxkd381Q/6qQuM1RESyBY1j3X1s7PnvzGxFoYvc/SEzG5Hn+COxp48BwzPkpara23fv51rJb8uWIF1BQ0SaRZbeUzvM7NDoiZkdQvnHa3wRuCv23IF7zGypmc3Md6GZzTSzTjPr3LhxY1kzFW/D0HgNEZFsJY3LgPvNbB1gBCPDLyhXBszsZIKgcUIs+QR3f8nM/ga418yedfeHcl3v7vMIqrZobW3NP7y9BBqvISKSoaTh7kuAwwhW7/t74Ah3v78cL25mHwT+A5jq7ptir/lS+PgKcDtwXDlerxQaryEikn/lvlPc/XdmNi1x6G/NDHe/rZQXNrODCdYcP8/dn4+l7wP0cffN4f5pwBWlvFY5RO0WX/kKbArD29571y4/IiK1kK96ahLwO+DTOY45wQ9+KjO7CTgJGGpmG4B2gl5YuPv1wDeBIcC1FgyG2B5OmvV+4PYwbS/gF+7+2+xvqbK2bt29v2mTelCJSHPJMsvtSHf/U6G0elCJWW7jNOOtiPQ2xc5ym6X31K050m7JnqXeQz2oRKTZ5WvTOBIYDeyXaNd4H9C/0hmrR+pBJSLNLl9J4wjgU8D+BO0a0TYB+HLls1Y/ovEa6kElIs0uS5vGh9390SrlpySVatMw2z0X1cKFwSjw9euhb1/YsSNo09DMtyLSiCqxct8TZnYJQVXVrmopd7+wB/lreFFg0DxUItKMsjSE3wh8APgE8CDBHFGbK5mpetDREZQwoqnRo/2OjvzzUImI9GZZqqeecPfxZrbS3T8YTov+sLsfX50sZleN6ikIpkbP9bGZwc6dZX95EZGKqUSX223h4xtmdjSwH/A3Pclcb5HWW6pPH62xISK9W5agMc/MBgH/DCwGnga+U9Fc1Zn4FOmQuxcVBI3iM2cqcIhI71WweqqRVHpEeNzChTBjRhAokjRCXEQaRdl6T5nZ1/Jd6O7fLSZjvUk0biOt/UIjxEWkt8rX5XZg+HgEcCxB1RQEA/z+WMlM1bs5c4LHlpbcI8Sjtg11vxWR3ia1TcPd57j7HIIuthPc/evu/nXgGEATZ6C2DRFpPlkawt8PvBt7/m6Y1lSS4zYAzj03GJ8RT4to3IaI9EZZgsbPgT+aWYeZdQB/AH5ayUzVo46OYGxGvN9A8nmS2jZEpLfJstzrXII1wV8Ptwvc/V8rnbFGonEbItIs8vWeep+7v2Vmg4GucIuODXb31yqfvfqUa9xGfC6qSNS2AWoUF5HeIXWchpn9X3f/lJn9iWB5112HAHf3Q6qRwWJUc5xGksZtiEgjKts0Iu7+qfBxpLsfEttGZg0YZjbfzF4xs6dSjpuZXW1ma8xspZlNiB2bYWarw21G1jdUK21t6eM2cnXLFRFpRKlBw8wm5Nsy3v+nwOQ8x08HDgu3mcB14WsPBtqBDwHHAe3hVCZ1La1tw0xtGyLSO+Qb3PfveY45cEqhm7v7Q2Y2Is8pU4Gfe1BH9piZ7W9mBwAnAfdG7SZmdi9B8Lmp0GvW0ty5cN55e/aocg+636pdQ0QaXWrQcPeTq/D6BwIvxp5vCNPS0vdgZjMJSikcXOPFutvagrEbuaxfr1HiItL4sqzcRzgl+lF0X7nv55XKVDHcfR4wD4KG8BpnJ3VqEVBPKhFpfAXHaZhZO/CDcDuZYFr0KWV6/ZeAg2LPh4dpael1L21qEQi65M6YAZ/7XHXzJCJSLllGhJ8JfAz4s7tfAIwlWIipHBYDfxf2ojoeeNPdXwbuBk4zs0FhA/hpYVrda2uDefPSj+/YAbfdtrthPJoxV0SkEWQJGlvdfSew3czeB7xC91JAKjO7CXgUOMLMNpjZF83sIjO7KDzlTmAdsAa4AbgYIGwA/xbweLhd0UiDCdvagmqqfGbMCAJHNGOuiEgjyNKm0Wlm+xP8qC8F/koQCApy9+kFjjtwScqx+cD8LK9Tj9JGiUd27EhvNBcRqVf5xmn80MwmuvvF7v6Gu18PfByYEVZTCenVS1E1Vd++he8RzZ6rqioRqXf5qqeeB64ysy4z+46ZjXf3LndfWa3MNYJ81UttbfCzn6U3jEcGDIAFCxQ0RKT+5ZtG5Pvu/mFgErAJmG9mz5pZu5kdXrUcNrgsJQ6tvSEijSLL1Ojr3f3f3H08MB34DPBMxXNWx5ILMhWqXspS4tD8VCLSCLKM09jLzD5tZguBu4DngGkVz1kdSy7IFD0mg0b8eaESh+anEpFGkK8h/ONmNp9gCo8vA78BDnX3c9z9P6uVwUaWbO+IShy5lod1390NV0SkXuUraXwDeAQY5e5T3P0X7v7fVcpXQ4hKElmrqSAIHGlLxEaLNilwiEi9ytcQfoq7/4e7v17NDDWSXNVUkyYFJYx8gSTfwL9oqhEFDhGpR1lGhEsRHnxwz0Di3j1o5JufCoISxwUXwNChwTrjI0YoiIhIfcg0y60Ullw3PJ9oltu05WEBtm2DTZuC/fXrNUOuiNQHlTTKoKMjd5XUpEnp12Qd+BfRWA4RqQcKGmWQq23DHR54YPfxXIqZagTghRdKzKiISIkUNCokHigKTTUydWq2ew4eXFKWRERKpqBRZlHbRjFTnt96azD3VKESx6ZNQeO4GsVFpFYUNMosXsLoyVQjhWzaFEypruAhIrWgoFFGyTmp4nJ1vU1qa4Np0wov4ARB8NBAQBGpNgWNMkprEI8fz3ctBFVVXV3ZAocGAopItSloVEGWdo7ksUIDACPRCoCqrhKRaqho0DCzyWb2nJmtMbPLcxz/P2a2PNyeN7M3Ysd2xI4trmQ+KyE+2K8niytF3XGHDMl2/qZNcN55cPHFxb+WiEhWFQsaZtYX+CFwOnAUMN3Mjoqf4+7/w93Hufs44AfAbbHDW6Nj7j6lUvmslChQ5Ft7o9C6HG1t8OqrQc+qLMHDHa67rnqlDq00KNJ8KlnSOA5Y4+7r3P1dYBGQb0TCdOCmCuanJtLaOaIf3LRjybU4ouCRZSBgtXpYFdOtWER6h0oGjQOBF2PPN4RpezCzFmAk8LtYcn8z6zSzx8zsM5XLZu0U08YBxU89ou65IlJu9dIQfg5wi7vHp+9rcfdW4AvA98zs0FwXmtnMMLh0bty4sRp57bF8kxpmnfCw2LYO2B08zEoPIMUudSsivUslg8ZLwEGx58PDtFzOIVE15e4vhY/rgAeA8bkudPd57t7q7q3Dhg0rNc8Vla8dIzqe5Qc5qq6aNSv3mJB8Si19FKpuE5HezTxtGblSb2y2F/A88DGCYPE48AV3X5U470jgt8BIDzNjZoOALe7+jpkNBR4Fprr70/les7W11Ts7O8v/ZirELH0Vv3zH4hYuhK98Zfc06sUYMCAotfR0uvWseRSR+mVmS8NanUwqVtJw9+3ApcDdwDPAze6+ysyuMLN4b6hzgEXePXqNAjrNbAVwP/DtQgGjt4r/BZ/rr/lie1jFlTo4sJg1RESkd6hYSaMWGq2kkewlletY/K/5Qn/ZR+t69ESfPrBzZzASfe5cLfYk0iyKLWkoaNS5YoJG8rohQ2pTbSUijaNuqqek5/I1lhfTW6mUaqtzz9Xa5CKyJwWNOpRv4sOsvZWi9oaozcM9++DAyPr1QfDo2zcIVAoiIqKg0YCylDKS53R0BAFgx45cZ+e3c2fwGAWRcg0WVDddkcajoFHn4j2UerIqYCRZeim2yiquXJMjahoSkcajoFHnCnW57amovSPLuh25RJMjRlVXe+2lKiyRZqCg0SB6On1HruPx9o6uriB4ZJ3PKimquoqqvQpVYWkaEpHGpi63DajYrrdZR5bPnh386Jd7pHfa2A+NKBepPXW5bSKl/nWenH69qyv4Ed+5s3vVVbHzWyWtXw8XXBCUPvr0URWWSCNT0GhAhRrEs1YB5WuITgaRnkyOGLdtW9CA7r67CgvUnVek0ShoNIBc3WfznVOJmWivvRZuvLG0Xle5JLvzKoiI1DcFjQYQLxGklSKydl8tpSE6PjliVHUVDRYstQorkjYmRA3lIvVBQaPB5CpFxMdyJH9ckzPRlqMUEq+62r49eI1yVGHlEq3/MWeOuvWK1AMFjTqVtUQQL2VE+5Ua25F2v+j1oyqsno79KCTZrVdVWSLVp6BRp7KUCNrbu3dZjfazBoos62EU03gO3UshpYz/yCJelXXeeXDqqUEAUQ8tkcpR0GhQ0doZ8eqgcgz8Syqlh1a0nnlLS3CspSWowip3YzoEQWrJkiCAxHtoqTQiUmbu3mu2Y445xnuj9vb8x2H3OdCzexS69+6yzu6t0GvmE8/PggXuLS3Bfcxyv1Y5t759uz+2tAR5EGlGQKcX8Ttb8x/6cm69NWgUEv/RTvsBz/fDHv2Axx/TgkSu+0Rp8UDQ0yDl7j5rVnWCR65tyBAFEGkuChpNKMuPdbxkkOtY/DHXsXipInmfXCWOnpQ+4uKlj6hEUM1A0qdP99dWqUR6q7oKGsBk4DlgDXB5juPnAxuB5eH2pdixGcDqcJuR5fWaNWikKVStFMkSNOLBI0tpptSgEUnmNR5MarWZBaUhaTyllIB7q7oJGkBfYC1wCPAeYAVwVOKc84Frclw7GFgXPg4K9wcVek0FjXTRD14kLaAkA0uhUkSh+ySDVLH/afMFnwULguqkWgWPZGkkXhJSNVd9KtcfM71JsUGjkr2njgPWuPs6d38XWARMzXjtJ4B73f01d38duJeg1CJFino5ReI9nqKfuGgfunfjTfbQSlu3PHmfqCtvtB/vUZVl5HrWLsNtbXDppbtHqMd7aFVqrEhcclr46DOA3YMS4723Lr54d5fgoUODrdxrkWjkvFRcMRGmmA04E/iP2PPzSJQqCEoaLwMrgVuAg8L0fwT+d+y8fwb+MeV1ZgKdQOfBBx9c7iDca2SpVoqXRpLnZql6KvY+ufIYv75QtVryfrmO52obqUUbSTFbKaUU/SW9p6zVtM2KOippZPFrYIS7f5CgNPGzYm/g7vPcvdXdW4cNG1b2DPYW+f4CjUoGWQb75ZNradrotYuddTdZenFPfw9RenR9cqzI+ecH10dTnsSnPoHKjBspRVRKMctdUomXTqISSzSgMZdmL31UYgLPplZMhClmAz4M3B17/g3gG3nO7wu8Ge5PB34UO/YjYHqh11SbRn5pf1llad8o1C6RtW0j7S/hfNcnzyt0bq7STbL3V9r11RwvUukt/h5ylVya8S9tlcT2RB01hO9F0IA9kt0N4aMT5xwQ2/8s8Fi4Pxj4E0Ej+KBwf3Ch11TQKF3aD29P7hHfTxsImK/qIBmscl2fL0Alz4lfn+t95utVtmBB7YNAObZ41+HofbW0BAEm3p04Lb3RNWOgLKRugkaQF84AnifoRTU7TLsCmBLu/yuwKgwo9wNHxq69kKCr7hrggiyvp6BRukoFjWTwiEsGlHx5iNImTSrfD412tPIAAAutSURBVGmyFJV2DrhPm9Z4bSTl2qLeYskg0tMfYv2A14e6ChrV3hQ0SpfsalvKPeL7+YJQWmCJP0/7IY9XeeV6zBcA4q+VL8/JkfK53k+h0fS9devp4Md8VZVSXQoaUjeKHVyYr70irTSSvD7XOdE90q5Pu1+uH7VCAS7t3Kh0Eh9XEv+BnTattmNOKrGljapPfgazZhVfFdbbSim1fD8KGlKXkj+qWQJK1msmTSp8TvJHPl9bSa5z8/04Jv9qzhW8sgbDWg9YrMctGXyiAFxPSp13Ld/7SfvOlivQKGhIXcr3nyLtWK70YmbWzfVDnrxXoR+sfI3jWQJUoWCRpaQSH2uy337pr5lsa2mmLa1UU0y1WSk/wvF/v0LfzULjjdKOJc8pV+BU0JC6lO8/ZNqXvyfXFHtOrnML/Qfu6VTxyf/8xbR/5GoDiAeo5LH29u49vpqlsT7fZub+sY/lnwgz3tjf2rrnuWnBp5igUejfP+0PCgWNCmwKGo2pJ3/hZbmmmPtm/U+f7z90vh+A+Lm50pLH4gEheW6hnmNpx+P3zlUqiarFktVA+Uo3zbxlCcD77bdnkMn1/UqmFduhorRSkoKGSNF6WiedLxCkvUahbr3RPeJpuc7N15srLT1K60kpJ1fJRSWYbFu+zydXR4EogMfbb5LftbTvWbEUNESqqNj66bRzS+05ljXAZNkKlWTSgmr0gxedl28WYG3FbdFnl6sHWqlrvShoiNRYsSWVLD3JCvUcy9eNOZkWDzrR81xpuR5zjdKP5zG5n7w+PtJ8yBD3vfcu/IMZBR8FncLbgAHFBw4FDZEGkq93Vtq5uY4l5Ton7d65GtmLGReTT7INqNhBkMmgOG1atjaWZg4wLS2F/13iFDREGliWH+QsQSNL+0mu8/PdJ/n6WfKRlCWY5btv8lj0XtLe57Rp6aWZ3hpYzIr9N1HQEGlY5e4VFteTH/n4a2YJPj3JQzJQFhs0kvu5rl+wIL2EkixpRX+tRyPUp01rrO7LKmkoaIiURSlBI9KT4JF1PEL8/KzX52tHySdf8MnX0J88J9ciX1GgKfTjXomOAmrTUNAQKZvyTTvR/bEn15b62vlkeZ/J+5SrhJevJJVWKkoLinvvvefYmXyBpVq9p2q9cp+IVEm5VqordYXHSsvyPpPvIcs1PblvofPa23evLJi8duvWYBXHaLVJ92C1yQULoKVlz3uuXx+s+FjxFQmLiTD1vqmkIVI9lRrJX8nrayGtGi6XnpbiSinBUWRJw4JreofW1lbv7OysdTZERHqkoyPYzIKSRVbFnt/9Wlvq7q1Zz1f1lIhInYiqloqtAqxmlaFKGiIiTayuShpmNtnMnjOzNWZ2eY7jXzOzp81spZktMbOW2LEdZrY83BZXMp8iIpLNXpW6sZn1BX4IfBzYADxuZovd/enYaU8Are6+xcxmAd8Bzg6PbXX3cZXKn4iIFK+SJY3jgDXuvs7d3wUWAVPjJ7j7/e6+JXz6GDC8gvkREZESVTJoHAi8GHu+IUxL80Xgrtjz/mbWaWaPmdln0i4ys5nheZ0bN24sLcciIpJXxaqnimFm5wKtwKRYcou7v2RmhwC/M7Mn3X1t8lp3nwfMg6AhvCoZFhFpUpUMGi8BB8WeDw/TujGzU4HZwCR3fydKd/eXwsd1ZvYAMB7YI2jELV269FUzW9/D/A4FXu3htbWiPFeH8lwdynN1JPOcY3x5uop1uTWzvYDngY8RBIvHgS+4+6rYOeOBW4DJ7r46lj4I2OLu75jZUOBRYGqiEb3c+e0spttZPVCeq0N5rg7luTpKzXPFShruvt3MLgXuBvoC8919lZldQTBsfTFwJbAv8CszA3jB3acAo4AfmdlOgnaXb1cyYIiISDYVbdNw9zuBOxNp34ztn5py3SPAmErmTUREiqdpRHabV+sM9IDyXB3Kc3Uoz9VRUp571TQiIiJSWSppiIhIZgoaIiKSWdMHjUKTKtYDMzvIzO4PJ3dcZWZfCdM7zOyl2MSOZ9Q6r3Fm1mVmT4Z56wzTBpvZvWa2OnwcVOt8RszsiNhnudzM3jKzr9bj52xm883sFTN7KpaW87O1wNXhd3ylmU2ok/xeaWbPhnm63cz2D9NHmNnW2Od9fbXzWyDfqd8HM/tG+Dk/Z2afqKM8/zKW3y4zWx6mF/9ZF7NiU2/bCLoCrwUOAd4DrACOqnW+cuTzAGBCuD+QYPzLUUAH8I+1zl+efHcBQxNp3wEuD/cvB/6t1vnM8934M8HAp7r7nIGPAhOApwp9tsAZBFP0GHA88Ic6ye9pwF7h/r/F8jsifl4dfs45vw/h/8kVwHuBkeFvS996yHPi+L8D3+zpZ93sJY2CkyrWA3d/2d2XhfubgWfIP49XPZsK/Czc/xmQOq9YjX0MWOvuPZ1hoKLc/SHgtURy2mc7Ffi5Bx4D9jezA6qT00Cu/Lr7Pe6+PXxalxOWpnzOaaYCi9z9HXf/E7CG4DemqvLl2YIBcWcBN/X0/s0eNIqdVLHmzGwEwZQqfwiTLg2L9/Prqaon5MA9ZrbUzGaGae9395fD/T8D769N1go6h+7/ser5c46kfbaN8D2/kO4Tlo40syfM7EEzO7FWmcoj1/ehET7nE4G/eGwGDor8rJs9aDQUM9sXuBX4qru/BVwHHAqMA14mKHbWkxPcfQJwOnCJmX00ftCD8nHd9fk2s/cAU4BfhUn1/jnvoV4/21zMbDawHVgYJr0MHOzu44GvAb8ws/fVKn85NNz3IWY63f8YKvqzbvagkWlSxXpgZv0IAsZCd78NwN3/4u473H0ncAM1KArn47snnXwFuJ0gf3+JqkbCx1dql8NUpwPL3P0vUP+fc0zaZ1u333MzOx/4FNAWBjrC6p1N4f5SgraBw2uWyYQ834e6/Zxh13yA04BfRmk9+aybPWg8DhxmZiPDvy7PAepuadmwHvLHwDPu/t1Yerxe+rPAU8lra8XM9jGzgdE+QaPnUwSf74zwtBnAf9Ymh3l1+2usnj/nhLTPdjHwd2EvquOBN2PVWDVjZpOB/wlM8d2LsWFmwyxY+RMLlkY4DFhXm1zuKc/3YTFwjpm918xGEuT7j9XOXx6nAs+6+4YooUefdbVb9uttI+hZ8jxBhJ1d6/yk5PEEgqqGlcDycDsDuBF4MkxfDBxQ67zG8nwIQU+SFcCq6LMFhgBLgNXAfcDgWuc1ke99gE3AfrG0uvucCYLay8A2grrzL6Z9tgS9pn4YfsefJFhiuR7yu4agDSD6Tl8fnvu58DuzHFgGfLrOPufU7wPBMg9rgeeA0+slz2H6T4GLEucW/VlrGhEREcms2aunRESkCAoaIiKSmYKGiIhkpqAhIiKZKWiIiEhmChoiBZjZDus++23ZZkMOZxmt13EfInuo6BrhIr3EVncfV+tMiNQDlTREeihcl+A7FqwZ8kcz+9swfYSZ/S6c0G6JmR0cpr8/XDdiRbh9JLxVXzO7wYK1Uu4xs73D8//BgjVUVprZohq9TZFuFDRECts7UT11duzYm+4+BrgG+F6Y9gPgZ+7+QYJJ+K4O068GHnT3sQTrHawK0w8Dfujuo4E3CEbpQrAmxvjwPhdV6s2JFEMjwkUKMLO/uvu+OdK7gFPcfV04oeSf3X2Imb1KMLXEtjD9ZXcfamYbgeHu/k7sHiOAe939sPD5PwH93P1fzOy3wF+BO4A73P2vFX6rIgWppCFSGk/ZL8Y7sf0d7G5r/CTBnFETgMfDWUpFakpBQ6Q0Z8ceHw33HyGYMRmgDXg43F8CzAIws75mtl/aTc2sD3CQu98P/BOwH7BHaUek2vSXi0hhe5vZ8tjz37p71O12kJmtJCgtTA/T/h74iZldBmwELgjTvwLMM7MvEpQoZhHMRppLX2BBGFgMuNrd3yjbOxLpIbVpiPRQ2KbR6u6v1jovItWi6ikREclMJQ0REclMJQ0REclMQUNERDJT0BARkcwUNEREJDMFDRERyez/A06QXsf8zuM6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSr5gnDLNRo7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdfbed2b-f7e2-4663-d7f5-9a76f369ed57"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)\n",
        "test_loss"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3583 - accuracy: 0.8868\n",
            "test_acc: 0.8867999911308289\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35827818512916565"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9SeN6QOO77D"
      },
      "source": [
        "model.save_weights('./cifar10.h5', overwrite=True)"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}